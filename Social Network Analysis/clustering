from sklearn import cluster
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import silhouette_score as siluet
from sklearn.metrics.cluster import homogeneity_score as purity
from sklearn.metrics import normalized_mutual_info_score as NMI

def jaccard_similarity(query, document):
    intersection = set(query).intersection(set(document))
    union = set(query).union(set(document))
    return len(intersection)/len(union)
def get_scores(group,tweets):
    scores = []
    for tweet in tweets:
        s = jaccard_similarity(group, tweet)
        scores.append(s)
    return scores

puan = 'puan maharani politik pdip iain sultan perempuan sayap ketua dpr '
prabowo = 'subianto gerindra 2019'
anies = 'baswedan aniesbaswedan jakarta nasdem gubernur dki'
ganjar = 'pranowo ganjarpranowo jateng jawa gubernur tengah pdip putih'

pu_scores = get_scores(puan, df.clean_tweet.to_list())
pr_scores = get_scores(prabowo, df.clean_tweet.to_list())
a_scores = get_scores(anies, df.clean_tweet.to_list())
g_scores = get_scores(ganjar, df.clean_tweet.to_list())

data = {'Username': df.Username.to_list(),       'Puan':pu_scores,
         'Prabowo': pr_scores, 'Anies':a_scores, 'Ganjar':g_scores}
scores_df = pd.DataFrame(data)

def get_classes(l1, l2, l3, l4):
    pu = []
    pr = []
    a = []
    g = []
    for i, j, k, l in zip(l1, l2, l3, l4):
        m = max(i, j, k, l)
        if m == i:
            pu.append(1)
        else:
            pu.append(0)
        if m == j:
            pr.append(1)
        else:
            pr.append(0)
        if m == k:
            a.append(1)
        else:
            a.append(0)
        if m == l:
            g.append(1)
        else:
            g.append(0)

    return pu, pr, a, g

l1 = scores_df.Puan.to_list()
l2 = scores_df.Prabowo.to_list()
l3 = scores_df.Anies.to_list()
l4 = scores_df.Ganjar.to_list()
pu, pr, a, g = get_classes(l1, l2, l3, l4)

data = {'name': scores_df.Username.to_list(), 'PuanM':pu, 'PrabowoS':pr, 'AniesB':a, 'GanjarP':g}
class_df = pd.DataFrame(data)

#grouping the tweets by username
new_groups_df = class_df.groupby(['name']).sum()

#add a new totals column
new_groups_df['total'] = new_groups_df['PuanM'] + new_groups_df['PrabowoS'] + new_groups_df['AniesB'] +  new_groups_df['GanjarP']

#add a new totals row
new_groups_df.loc["Total"] = new_groups_df.sum()

new_groups_df

fig = plt.figure(figsize =(10, 7))
a = new_groups_df.drop(['total'], axis = 1)
plt.pie(a.loc['Total'], labels = a.columns)
plt.title('A pie chart showing the volumes of tweets under different categories.')
plt.show()

X = new_groups_df[['PuanM', 'PrabowoS', 'AniesB', 'GanjarP']]
min_max_scaler = MinMaxScaler()
dfX = pd.DataFrame(min_max_scaler.fit_transform(X), columns=['PuanM', 'PrabowoS', 'AniesB', 'GanjarP'])

distorsions, k1, kN = [], 2, 10
for k in range(k1, kN):
    kmeans = cluster.KMeans(n_clusters=k).fit(dfX)
    distorsions.append(kmeans.inertia_)

plt.plot(range(k1, kN), distorsions); plt.grid(True)
plt.title('Elbow curve')

k = 4
km = cluster.KMeans(n_clusters=k, init='random', max_iter=300, tol=0.0001, random_state = 0)
km.fit(dfX)
# The Result of Clustering
C_km = km.predict(dfX)
p= sns.countplot(x=C_km)

g = sns.pairplot(dfX.assign(kmeans = C_km), hue="kmeans", diag_kind="hist", palette="tab10")

# KMPP
k = 3
kmPP = cluster.KMeans(n_clusters=k, init='k-means++', max_iter=300, tol=0.0001, random_state = random_state)
kmPP.fit(dfX)
C_kmpp = kmPP.predict(dfX)
sns.countplot(x=C_kmpp)
C_kmpp[:10]

g = sns.pairplot(dfX.assign(kmeanspp = C_kmpp), hue="kmeanspp", diag_kind="hist", palette="tab10")
